msleep_new <- msleep %>%
group_by(vore) %>%
summarise(mean_sleep = mean(sleep_total))
msleep_new <- msleep %>%
filter(sleep_total>2 & sleep_total<19) %>%
group_by(vore) %>%
summarise(mean_sleep = mean(sleep_total))
msleep_new <- msleep %>%
filter(sleep_total>2 & sleep_total<19, !conservation %in% "domesticated") %>%
group_by(vore) %>%
summarise(mean_sleep = mean(sleep_total))
msleep_new <- msleep %>%
na.omit() %>%
filter(sleep_total>2 & sleep_total<19, !conservation!="domesticated") %>%
group_by(vore) %>%
summarise(mean_sleep = mean(sleep_total))
msleep <- msleep %>% mutate(bra_bo_ratio = brainwt*100/bodywt)
msleep <- msleep %>%
mutate(animal_count = row_number())
msleep <- msleep %>%
arrange(desc(animal_count))
calendarHeat <- function(dates,
values,
ncolors=99,
color="r2g",
varname="Values",
date.form = "%Y-%m-%d", ...) {
require(lattice)
require(grid)
require(chron)
if (class(dates) == "character" | class(dates) == "factor" ) {
dates <- strptime(dates, date.form)
}
caldat <- data.frame(value = values, dates = dates)
min.date <- as.Date(paste(format(min(dates), "%Y"),
"-1-1",sep = ""))
max.date <- as.Date(paste(format(max(dates), "%Y"),
"-12-31", sep = ""))
dates.f <- data.frame(date.seq = seq(min.date, max.date, by="days"))
# Merge moves data by one day, avoid
caldat <- data.frame(date.seq = seq(min.date, max.date, by="days"), value = NA)
dates <- as.Date(dates)
caldat$value[match(dates, caldat$date.seq)] <- values
caldat$dotw <- as.numeric(format(caldat$date.seq, "%w"))
caldat$woty <- as.numeric(format(caldat$date.seq, "%U")) + 1
caldat$yr <- as.factor(format(caldat$date.seq, "%Y"))
caldat$month <- as.numeric(format(caldat$date.seq, "%m"))
yrs <- as.character(unique(caldat$yr))
d.loc <- as.numeric()
for (m in min(yrs):max(yrs)) {
d.subset <- which(caldat$yr == m)
sub.seq <- seq(1,length(d.subset))
d.loc <- c(d.loc, sub.seq)
}
caldat <- cbind(caldat, seq=d.loc)
#color styles
r2b <- c("#0571B0", "#92C5DE", "#F7F7F7", "#F4A582", "#CA0020") #red to blue
r2g <- c("#D61818", "#FFAE63", "#FFFFBD", "#B5E384")   #red to green
w2b <- c("#045A8D", "#2B8CBE", "#74A9CF", "#BDC9E1", "#F1EEF6")   #white to blue
g2r <- c("#B5E384", "#FFFFBD", "#FFAE63", "#D61818") #green to red
assign("col.sty", get(color))
calendar.pal <- colorRampPalette((col.sty), space = "Lab")
def.theme <- lattice.getOption("default.theme")
cal.theme <-
function() {
theme <-
list(
strip.background = list(col = "transparent"),
strip.border = list(col = "transparent"),
axis.line = list(col="transparent"),
par.strip.text=list(cex=0.8))
}
lattice.options(default.theme = cal.theme)
yrs <- (unique(caldat$yr))
nyr <- length(yrs)
print(cal.plot <- levelplot(value~woty*dotw | yr, data=caldat,
as.table=TRUE,
aspect=.12,
layout = c(1, nyr%%7),
between = list(x=0, y=c(1,1)),
strip=TRUE,
main = paste("Calendar Heat Map of ", varname, sep = ""),
scales = list(
x = list(
at= c(seq(2.9, 52, by=4.42)),
labels = month.abb,
alternating = c(1, rep(0, (nyr-1))),
tck=0,
cex = 0.7),
y=list(
at = c(0, 1, 2, 3, 4, 5, 6),
labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday",
"Friday", "Saturday"),
alternating = 1,
cex = 0.6,
tck=0)),
xlim =c(0.4, 54.6),
ylim=c(6.6,-0.6),
cuts= ncolors - 1,
col.regions = (calendar.pal(ncolors)),
xlab="" ,
ylab="",
colorkey= list(col = calendar.pal(ncolors), width = 0.6, height = 0.5),
subscripts=TRUE
) )
panel.locs <- trellis.currentLayout()
for (row in 1:nrow(panel.locs)) {
for (column in 1:ncol(panel.locs))  {
if (panel.locs[row, column] > 0)
{
trellis.focus("panel", row = row, column = column,
highlight = FALSE)
xyetc <- trellis.panelArgs()
subs <- caldat[xyetc$subscripts,]
dates.fsubs <- caldat[caldat$yr == unique(subs$yr),]
y.start <- dates.fsubs$dotw[1]
y.end   <- dates.fsubs$dotw[nrow(dates.fsubs)]
dates.len <- nrow(dates.fsubs)
adj.start <- dates.fsubs$woty[1]
for (k in 0:6) {
if (k < y.start) {
x.start <- adj.start + 0.5
} else {
x.start <- adj.start - 0.5
}
if (k > y.end) {
x.finis <- dates.fsubs$woty[nrow(dates.fsubs)] - 0.5
} else {
x.finis <- dates.fsubs$woty[nrow(dates.fsubs)] + 0.5
}
grid.lines(x = c(x.start, x.finis), y = c(k -0.5, k - 0.5),
default.units = "native", gp=gpar(col = "grey", lwd = 1))
}
if (adj.start <  2) {
grid.lines(x = c( 0.5,  0.5), y = c(6.5, y.start-0.5),
default.units = "native", gp=gpar(col = "grey", lwd = 1))
grid.lines(x = c(1.5, 1.5), y = c(6.5, -0.5), default.units = "native",
gp=gpar(col = "grey", lwd = 1))
grid.lines(x = c(x.finis, x.finis),
y = c(dates.fsubs$dotw[dates.len] -0.5, -0.5), default.units = "native",
gp=gpar(col = "grey", lwd = 1))
if (dates.fsubs$dotw[dates.len] != 6) {
grid.lines(x = c(x.finis + 1, x.finis + 1),
y = c(dates.fsubs$dotw[dates.len] -0.5, -0.5), default.units = "native",
gp=gpar(col = "grey", lwd = 1))
}
grid.lines(x = c(x.finis, x.finis),
y = c(dates.fsubs$dotw[dates.len] -0.5, -0.5), default.units = "native",
gp=gpar(col = "grey", lwd = 1))
}
for (n in 1:51) {
grid.lines(x = c(n + 1.5, n + 1.5),
y = c(-0.5, 6.5), default.units = "native", gp=gpar(col = "grey", lwd = 1))
}
x.start <- adj.start - 0.5
if (y.start > 0) {
grid.lines(x = c(x.start, x.start + 1),
y = c(y.start - 0.5, y.start -  0.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
grid.lines(x = c(x.start + 1, x.start + 1),
y = c(y.start - 0.5 , -0.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
grid.lines(x = c(x.start, x.start),
y = c(y.start - 0.5, 6.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
if (y.end < 6  ) {
grid.lines(x = c(x.start + 1, x.finis + 1),
y = c(-0.5, -0.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
grid.lines(x = c(x.start, x.finis),
y = c(6.5, 6.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
} else {
grid.lines(x = c(x.start + 1, x.finis),
y = c(-0.5, -0.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
grid.lines(x = c(x.start, x.finis),
y = c(6.5, 6.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
}
} else {
grid.lines(x = c(x.start, x.start),
y = c( - 0.5, 6.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
}
if (y.start == 0 ) {
if (y.end < 6  ) {
grid.lines(x = c(x.start, x.finis + 1),
y = c(-0.5, -0.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
grid.lines(x = c(x.start, x.finis),
y = c(6.5, 6.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
} else {
grid.lines(x = c(x.start + 1, x.finis),
y = c(-0.5, -0.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
grid.lines(x = c(x.start, x.finis),
y = c(6.5, 6.5), default.units = "native",
gp=gpar(col = "black", lwd = 1.75))
}
}
for (j in 1:12)  {
last.month <- max(dates.fsubs$seq[dates.fsubs$month == j])
x.last.m <- dates.fsubs$woty[last.month] + 0.5
y.last.m <- dates.fsubs$dotw[last.month] + 0.5
grid.lines(x = c(x.last.m, x.last.m), y = c(-0.5, y.last.m),
default.units = "native", gp=gpar(col = "black", lwd = 1.75))
if ((y.last.m) < 6) {
grid.lines(x = c(x.last.m, x.last.m - 1), y = c(y.last.m, y.last.m),
default.units = "native", gp=gpar(col = "black", lwd = 1.75))
grid.lines(x = c(x.last.m - 1, x.last.m - 1), y = c(y.last.m, 6.5),
default.units = "native", gp=gpar(col = "black", lwd = 1.75))
} else {
grid.lines(x = c(x.last.m, x.last.m), y = c(- 0.5, 6.5),
default.units = "native", gp=gpar(col = "black", lwd = 1.75))
}
}
}
}
trellis.unfocus()
}
lattice.options(default.theme = def.theme)
}
## Example of use: Plot financial data
## This code is not run.
if(FALSE) {
#create faux data; skip this to use data from a file or stock data
#ndays <- 1500   #set number of days
#dates <- as.POSIXlt(seq(Sys.Date()- ndays, Sys.Date() - 1, by="days"))
#vals <- runif(ndays, -100, 100)
#stock data:
stock <- "MSFT"
start.date <- "2006-01-12"
end.date <- Sys.Date()
quote <- paste("http://ichart.finance.yahoo.com/table.csv?s=",
stock,
"&a=", substr(start.date,6,7),
"&b=", substr(start.date, 9, 10),
"&c=", substr(start.date, 1,4),
"&d=", substr(end.date,6,7),
"&e=", substr(end.date, 9, 10),
"&f=", substr(end.date, 1,4),
"&g=d&ignore=.csv", sep="")
stock.data <- read.csv(quote, as.is=TRUE)
# Plot as calendar heatmap
calendarHeat(stock.data$Date, stock.data$Adj.Close, varname="MSFT Adjusted Close")
}
# Plot as calendar heatmap
calendarHeat(stock.data$Date, stock.data$Adj.Close, varname="MSFT Adjusted Close")
install.packages("grid")
install.packages("grid")
#### 0. INCLUDES ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi, dplyr,magrittr, tidyr, reshape2, readxl, stringi,
ggplot2,caret,corrplot,rpart,gdata,chron,
esquisse,RMySQL,lubridate,padr,httr)
# Setwd (1º current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
#Create a database connection
con = dbConnect(MySQL(), user='deepAnalytics', password='Sqltask1234!',
dbname='dataanalytics2018', host='data-analytics-2018.cbrosir2cswx.us-east-1.rds.amazonaws.com')
#downloading yr_2007 table
yr_2007<- dbGetQuery(con, "SELECT * FROM yr_2007")
#downloading yr_2008 table
yr_2008<- dbGetQuery(con, "SELECT * FROM yr_2008")
#downloading yr_2009 table
yr_2009<- dbGetQuery(con, "SELECT * FROM yr_2009")
entire_years<- bind_rows(yr_2007, yr_2008, yr_2009)
## Combine Date and Time attribute values in a new attribute column
entire_years <-cbind(entire_years,paste(entire_years$Date,entire_years$Time), stringsAsFactors=FALSE)
## Give the new attribute (in the 11th column) a header name
## NOTE: if you downloaded more than 5 attributes you will need to change the column number)
colnames(entire_years)[11] <-"DateTime"
#remove Date and Time columns
entire_years$Date <- NULL
entire_years$Time <- NULL
# Move the DateTime attribute to the first position, from the last position, within the dataset
entire_years <- entire_years[,c(ncol(entire_years), 1:(ncol(entire_years)-1))]
#everything into Kw/h -> standard market measure
entire_years <- entire_years %>% mutate(Global_active_power = Global_active_power/60) #kw into kw/h
entire_years <- entire_years %>% mutate(Global_reactive_power = Global_reactive_power/60) #kw into kw/h
entire_years <- entire_years %>% mutate(Sub_metering_1 = Sub_metering_1/1000) #w/h into kw/h
entire_years <- entire_years %>% mutate(Sub_metering_2 = Sub_metering_2/1000) #w/h into kw/h
entire_years <- entire_years %>% mutate(Sub_metering_3 = Sub_metering_3/1000) #w/h into kw/h
#After converting from POSIXlt to POSIXct we will add the time zone and we'll prevent warning messages.
## Convert DateTime from POSIXlt to POSIXct
entire_years$DateTime <- as.POSIXct(entire_years$DateTime, "%Y/%m/%d %H:%M:%S")
View(entire_years)
remove(yr_2007, yr_2008, yr_2009)
#complete the data adding rows where missing rows are
complete_rows <- pad(entire_years, by="DateTime", break_above = 3)
#creating a sequence to check how many rows would be in the dataset
length(seq(from=ymd_hm("2007-01-01 00:00"), to=ymd_hm("2009-12-31 23:59"), by=60))
remove(complete_rows)
#complete the data adding rows where missing rows are
complete_rows <- pad(entire_years, by="DateTime", break_above = 2)
#complete the data adding rows where missing rows are
entire_years <- pad(entire_years, by="DateTime", break_above = 2)
remove (con)
remove (complete_rows)
## Create "year" attribute with lubridate
entire_years$year<-year(entire_years$DateTime)
#Create "quarter" attribute
entire_years$quarter<-quarter(entire_years$DateTime)
#Create "month" attribute
entire_years$month<-month(entire_years$DateTime)
#Create "week" attribute
entire_years$week<-week(entire_years$DateTime)
#Create "weekday" attribute
entire_years$weekday<-weekdays(entire_years$DateTime)
#Create "day" attribute
entire_years$day<-day(entire_years$DateTime)
#Create "hour" attribute
entire_years$hour<-hour(entire_years$DateTime)
#Create "minute" attribute
entire_years$minute<-minute(entire_years$DateTime)
View(entire_years)
# creating residual active energy feature (global_active_power - sub_metering_1 -
#sub_metering_2 - sub_metering_3)
entire_years$residual <- (entire_years$Global_active_power - entire_years$Sub_metering_1 -
entire_years$Sub_metering_2 - entire_years$Sub_metering_3)
#creating monthly prices
entire_day <- filter(entire_years, hour %in% c(6:22))
entire_night <- filter(entire_years, hour %in% c(0,1,2,3,4,5,23))
#creating cost column in both df
entire_day<-mutate(entire_day, cost_total = Global_active_power * 0.158)
entire_night<-mutate(entire_night, cost_total = Global_active_power * 0.123)
#calculating daily rates for each submeter in day rate
entire_day <- entire_day %>% mutate(cost_sub1 = Sub_metering_1*0.158)
entire_day <- entire_day %>% mutate(cost_sub2 = Sub_metering_2*0.158)
entire_day <- entire_day %>% mutate(cost_sub3 = Sub_metering_3*0.158)
entire_day <- entire_day %>% mutate(cost_residual = residual*0.158)
#calculating nightly rates for each submeter in night rate
entire_night <- entire_night %>% mutate(cost_sub1 = Sub_metering_1*0.123)
entire_night <- entire_night %>% mutate(cost_sub2 = Sub_metering_2*0.123)
entire_night <- entire_night %>% mutate(cost_sub3 = Sub_metering_3*0.123)
entire_night <- entire_night %>% mutate(cost_residual = residual*0.123)
1117920+1578240
1117290+460320
1117920+460320
#merging night and day data frames into a unique dataframe
entire_ok<-bind_rows(entire_day, entire_night)
#arranging data frame for DateTime
entire_ok<-arrange(entire_ok, DateTime)
View(entire_ok)
remove(entire_day, entire_night, entire)
remove(entire_years)
#saving pre-processed data frame
save(entire_ok, file="entire_ok.Rda")
paste(entire_ok$hour, entire_ok$minute)
x<-paste(entire_ok$hour, entire_ok$minute)
str(x)
hm(x)
entire_ok$hour_minute<-paste(entire_ok$hour, entire_ok$minute)
entire_ok$hour_minute<-hm(paste(entire_ok$hour, entire_ok$minute))
View(entire_ok)
entire_ok$day_rate <- ifelse (between(entire_ok$hour_minute, "6H 30M 0S", "22H 30M 0S"), 0.15, 0.12)
hm("6:30")
entire_ok$day_rate <- ifelse (between(entire_ok$hour_minute, hm("6:30"), hm("22:30")), 0.15, 0.12)
View(entire_ok)
hm("22:30")
between(entire_ok$hour_minute, hm("6:30"), hm("22:30")
(between(entire_ok$hour_minute, hm("6:30"), hm("22:30")
between(entire_ok$hour_minute, hm("6:30"), hm("22:30"))
entire_ok$day_rate <- ifelse (between(entire_ok$hour_minute, hm("6:30"), hm("22:30")), 0.12, 0.15)
summary(hour_minute)
summary(entire_ok$hour_minute)
summary(entire_ok$day_rate)
entire_ok$day_rate <- ifelse (entire_ok$hour_minute >= hm("6:30") & entire_ok$hour_minute <= hm("22:30"), 0.12, 0.15)
summary(entire_ok$day_rate)
entire_ok$day_rate <- ifelse (entire_ok$hour_minute >= hm("6:30") & entire_ok$hour_minute <= hm("22:30"), 0.15, 0.12)
between(entire_ok$hour_minute, hm("6:30"), hm("22:30"))
between(entire_ok$hour_minute, 6, 2)
test <- ifelse (between(entire_ok$Global_active_power, 0.02, 0.04), 0.12, 0.15)
str(test)
summary(test)
View(entire_ok)
#### 0. INCLUDES ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi, dplyr,magrittr, tidyr, reshape2, readxl, stringi,
ggplot2,caret,corrplot,rpart,gdata,chron,
esquisse,RMySQL,lubridate,padr,httr)
# Setwd (1º current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
#Create a database connection
con = dbConnect(MySQL(), user='deepAnalytics', password='Sqltask1234!',
dbname='dataanalytics2018', host='data-analytics-2018.cbrosir2cswx.us-east-1.rds.amazonaws.com')
#downloading yr_2007 table
yr_2007<- dbGetQuery(con, "SELECT * FROM yr_2007")
#downloading yr_2008 table
yr_2008<- dbGetQuery(con, "SELECT * FROM yr_2008")
#downloading yr_2009 table
yr_2009<- dbGetQuery(con, "SELECT * FROM yr_2009")
#create a Multi-Year data frame only with complete years. Combine tables into one dataframe using dplyr
entire_years<- bind_rows(yr_2007, yr_2008, yr_2009)
## Combine Date and Time attribute values in a new attribute column
entire_years <-cbind(entire_years,paste(entire_years$Date,entire_years$Time), stringsAsFactors=FALSE)
## Give the new attribute (in the 11th column) a header name
## NOTE: if you downloaded more than 5 attributes you will need to change the column number)
colnames(entire_years)[11] <-"DateTime"
#remove Date and Time columns
entire_years$Date <- NULL
entire_years$Time <- NULL
# Move the DateTime attribute to the first position, from the last position, within the dataset
entire_years <- entire_years[,c(ncol(entire_years), 1:(ncol(entire_years)-1))]
## Convert DateTime from POSIXlt to POSIXct
entire_years$DateTime <- as.POSIXct(entire_years$DateTime, "%Y/%m/%d %H:%M:%S")
#converting values into Kw/h -> standard market measure
entire_years <- entire_years %>% mutate(Global_active_power = Global_active_power/60) #kw into kw/h
entire_years <- entire_years %>% mutate(Global_reactive_power = Global_reactive_power/60) #kw into kw/h
entire_years <- entire_years %>% mutate(Sub_metering_1 = Sub_metering_1/1000) #w/h into kw/h
entire_years <- entire_years %>% mutate(Sub_metering_2 = Sub_metering_2/1000) #w/h into kw/h
entire_years <- entire_years %>% mutate(Sub_metering_3 = Sub_metering_3/1000) #w/h into kw/h
#creating a sequence to check how many rows would be in a complete dataset
length(seq(from=ymd_hm("2007-01-01 00:00"), to=ymd_hm("2009-12-31 23:59"), by=60)) #-> 1578240
#complete the data adding rows where missing rows are
entire_years <- pad(entire_years, by="DateTime", break_above = 2)
## Creating new attributes (with lubridate)
#year
entire_years$year<-year(entire_years$DateTime)
#quarter
entire_years$quarter<-quarter(entire_years$DateTime)
#month
entire_years$month<-month(entire_years$DateTime)
#week
entire_years$week<-week(entire_years$DateTime)
#weekday
entire_years$weekday<-weekdays(entire_years$DateTime)
#day
entire_years$day<-day(entire_years$DateTime)
#hour
entire_years$hour<-hour(entire_years$DateTime)
#minute
entire_years$minute<-minute(entire_years$DateTime)
View(entire_years)
# creating residual active energy feature (global_active_power - sub_metering_1 -
#sub_metering_2 - sub_metering_3)
entire_years$residual <- (entire_years$Global_active_power - entire_years$Sub_metering_1 -
entire_years$Sub_metering_2 - entire_years$Sub_metering_3)
#Assigning day and night rates: 0.123€ from 22:31-6:29 & 0.158€ from 6:30-22:30
#creating a column to paste hour and minutes
entire_years$hour_minute<-hm(paste(entire_years$hour, entire_years$minute))
View(entire_years)
#creating a column with the rate for each period of time (between 6:30 & 22:30, true, false)
entire_years$day_rate <- ifelse (entire_years$hour_minute >= hm("6:30") & entire_years$hour_minute <= hm("22:30"), 0.158, 0.123)
entire_years$day_rate <- NULL
View(entire_years)
#creating a column with the rate for each period of time (between 6:30 & 22:30, true, false)
entire_years$rate <- ifelse (entire_years$hour_minute >= hm("6:30") & entire_years$hour_minute <= hm("22:30"), 0.158, 0.123)
#calculating cost for each submeter
entire_years <- entire_years %>% mutate(cost_sub1 = Sub_metering_1*rate)
View(entire_years)
entire_years$cost_sub1<-NULL
entire_years$cost_total<- entire_years$Global_active_power*entire_years$rate
View(entire_years)
entire_years$cost_residual<- entire_years$residual*entire_years$rate
entire_years$cost_sub1<- entire_years$Sub_metering_1*entire_years$rate
entire_years$cost_sub1<- entire_years$Sub_metering_1*entire_years$rate
entire_years$cost_sub2<- entire_years$Sub_metering_2*entire_years$rate
entire_years$cost_sub3<- entire_years$Sub_metering_3*entire_years$rate
#removing unnecesary data frames
remove(con, yr_2007, yr_2008, yr_2009)
#saving pre-processed data frame
save(entire_years, file="entire_years.Rda")
#saving pre-processed data frame
save(entire_years, file="entire_ok.Rda")
#load data frame
load("../Task1.IoT_Exploratory_data_analysis/datasets/entire_ok.Rda")
View(entire_years)
#saving the data frame as entire_ok to be able to use the plotting code
entire_ok <- entire_years
#saving pre-processed data frame
save(entire_ok, file="entire_ok.Rda")
pacman::p_load(rstudioapi,dplyr,tidyr,ggplot2,caret,rpart,gdata,chron,lubridate,padr)
#### 0. INCLUDES ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi,dplyr,tidyr,ggplot2,caret,rpart,gdata,chron,lubridate,padr)
# Setwd (1º current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
#### 0. INCLUDES ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi,dplyr,tidyr,ggplot2,caret,rpart,gdata,chron,lubridate,padr)
# Setwd (1º current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
#load data frame
load("../Task1.IoT_Exploratory_data_analysis/datasets/entire_ok.Rda")
